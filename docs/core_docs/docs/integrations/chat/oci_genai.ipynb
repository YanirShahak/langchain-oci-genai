{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Oracle Cloud Infrastructure Generative AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Oracle Cloud Infrastructure (OCI) Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases, and which is available through a single API.\n",
        "Using the OCI Generative AI service you can access ready-to-use pretrained models, or create and host your own fine-tuned custom models based on your own data on dedicated AI clusters. Detailed documentation of the service and API is available [here](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm) and [here](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai/20231130/).\n",
        "\n",
        "This notebook explains how to use OCI's Genrative AI models with LangChainJS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "In order to use this integration you will need the following:\n",
        "1. An OCI tenancy. If you do not already have and account, please create one [here](https://signup.cloud.oracle.com?sourceType=:ex:of:::::LangChainJSIntegration&SC=:ex:of:::::LangChainJSIntegration&pcode=).\n",
        "2. Setup an [authentication method](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdk_authentication_methods.htm) (Using a [configuration file](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdkconfig.htm) with [API Key authentication](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/apisigningkey.htm#apisigningkey_topic_How_to_Generate_an_API_Signing_Key_Console) is the simplest to start with).\n",
        "3. Please make sure that your OCI tenancy is registered in one of the [supported regions](https://docs.oracle.com/en-us/iaas/Content/generative-ai/overview.htm#regions).\n",
        "4. You will need the ID (aka OCID) of a compartment in which your OCI user has [access to use the Generative AI service](https://docs.oracle.com/en-us/iaas/Content/generative-ai/iam-policies.htm). You can either use the `root` compartment or [create your own](https://docs.oracle.com/en-us/iaas/Content/Identity/compartments/To_create_a_compartment.htm).\n",
        "5. Retrieve the desired model name from the [available models](https://docs.oracle.com/en-us/iaas/Content/generative-ai/pretrained-models.htm) list (please make sure not to select a deprecated model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "The integration makes use of the [OCI TypeScript SDK](https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/typescriptsdk.htm).\n",
        "To install the integration dependencies, execute the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "npm install oci-common oci-generativeaiinference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instantiation\n",
        "The OCI Generative AI service supports two groups of LLMs:\n",
        "1. Cohere family of LLMs.\n",
        "2. Generic family of LLMs which include model such as Llama.\n",
        "\n",
        "The following code demonstrates how to create an instance for each of the families.\n",
        "The only mandatory two parameters are:\n",
        "1. `compartmentId` - A compartment OCID in which the user you are using for authentication was granted permissions to access the Generative AI service.\n",
        "2. `onDemandModelId` or `dedicatedEndpointId` - Either a [pre-trained model](https://docs.oracle.com/en-us/iaas/Content/generative-ai/pretrained-models.htm) name/OCID or a dedicated endpoint OCID for an endpoint configured on a [dedicated AI cluster (DAC)](https://docs.oracle.com/en-us/iaas/Content/generative-ai/ai-cluster.htm). Either `onDemandModelId` or `dedicatedEndpointId` must be provided but not both.\n",
        "\n",
        "In this example, since no other parameters are specified, a default SDK client will be created with the following configuration:\n",
        "1. Authentication will be attempted using a [configuration file](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdkconfig.htm) which should be already setup and available under `~/.oci/config`. The `config` file is expected to contain a `DEFAULT` profile with the correct information. Please see the prerequisites for more information.\n",
        "2. The retry strategy will be set to a single attempt. If the first API call was not successful, the request will fail.\n",
        "3. The region will be set to `us-chicago-1`. Please make sure that your tenancy is registered this region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "javascript"
        }
      },
      "outputs": [],
      "source": [
        "import { OciGenAiCohereChat } from \"@langchain/community/chat_models/oci_genai/cohere_chat\";\n",
        "import { OciGenAiGenericChat } from \"@langchain/community/chat_models/oci_genai/generic_chat\";\n",
        "\n",
        "const cohereLlm = new OciGenAiCohereChat({\n",
        "  compartmentId: \"oci.compartment...\",\n",
        "  onDemandModelId: \"cohere.command-r-plus-08-2024\",\n",
        "  // dedicatedEndpointId: \"oci.dedicatedendpoint...\"\n",
        "});\n",
        "\n",
        "const genericLlm = new OciGenAiGenericChat({\n",
        "  compartmentId: \"oci.compartment...\",\n",
        "  onDemandModelId: \"meta.llama-3.3-70b-instruct\",\n",
        "  // dedicatedEndpointId: \"oci.dedicatedendpoint...\"\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SDK client options\n",
        "The above example used default values to create the SDK client behind the scenes.\n",
        "If you need more control in the creation of the client, here are additional options (the options are the same for `OciGenAiCohereChat` and `OciGenAiGenericChat`).\n",
        "\n",
        "The first example will create an SDK client with the following configuration:\n",
        "1. [Instance Principal authentication](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdk_authentication_methods.htm#sdk_authentication_methods_instance_principaldita). Please note that this authentication method requires [configuration](https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/callingservicesfrominstances.htm).\n",
        "2. Using the Sao Paulo region.\n",
        "3. Up to 3 attempts will be made in case API calls fail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "javascript"
        }
      },
      "outputs": [],
      "source": [
        "import { MaxAttemptsTerminationStrategy, Region } from \"oci-common\"\n",
        "import { OciGenAiCohereChat } from \"@langchain/community/chat_models/oci_genai/cohere_chat\";\n",
        "import { OciGenAiNewClientAuthType } from \"@langchain/community/chat_models/oci_genai/types\";\n",
        "\n",
        "const cohereLlm = new OciGenAiCohereChat({\n",
        "  compartmentId: \"oci.compartment...\",\n",
        "  onDemandModelId: \"cohere.command-r-plus-08-2024\",\n",
        "  newClientParams: {\n",
        "    authType: OciGenAiNewClientAuthType.InstancePrincipal,\n",
        "    regionId: Region.SA_SAOPAULO_1.regionId,\n",
        "    clientConfiguration: {\n",
        "      retryConfiguration: {\n",
        "        terminationStrategy: new MaxAttemptsTerminationStrategy(3)\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second example will create an SDK client with the following configuration:\n",
        "1. Config file authentication.\n",
        "1. Use the config file: `/my/path/config`.\n",
        "1. Use the details under the `MY_PROFILE_IN_CONFIG_FILE` profile in the specified config file.\n",
        "1. The retry strategy will be set to a single attempt. If the first API call was not successful, the request will fail.\n",
        "1. The region will be set to `us-chicago-1`. Please make sure that your tenancy is registered this region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "javascript"
        }
      },
      "outputs": [],
      "source": [
        "import { OciGenAiCohereChat } from \"@langchain/community/chat_models/oci_genai/cohere_chat\";\n",
        "import { OciGenAiNewClientAuthType } from \"@langchain/community/chat_models/oci_genai/types\";\n",
        "\n",
        "const cohereLlm = new OciGenAiCohereChat({\n",
        "  compartmentId: \"oci.compartment...\",\n",
        "  onDemandModelId: \"cohere.command-r-plus-08-2024\",\n",
        "  newClientParams: {\n",
        "    authType: OciGenAiNewClientAuthType.ConfigFile,\n",
        "    authParams: {\n",
        "      clientConfigFilePath: \"/my/path/config\",\n",
        "      clientProfile: \"MY_PROFILE_IN_CONFIG_FILE\"\n",
        "    }\n",
        "  }\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The third example will create an SDK client with the following configuration:\n",
        "1. Config file authentication.\n",
        "1. Use [Resource Principal](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdk_authentication_methods.htm#sdk_authentication_methods_resource_principal) authentication.\n",
        "1. The retry strategy will be set to a single attempt. If the first API call was not successful, the request will fail.\n",
        "1. The region will be set to `us-chicago-1`. Please make sure that your tenancy is registered this region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "javascript"
        }
      },
      "outputs": [],
      "source": [
        "import { OciGenAiCohereChat } from \"@langchain/community/chat_models/oci_genai/cohere_chat\";\n",
        "import { OciGenAiNewClientAuthType } from \"@langchain/community/chat_models/oci_genai/types\";\n",
        "\n",
        "const cohereLlm = new OciGenAiCohereChat({\n",
        "  compartmentId: \"oci.compartment...\",\n",
        "  onDemandModelId: \"cohere.command-r-plus-08-2024\",\n",
        "  newClientParams: {\n",
        "    authType: OciGenAiNewClientAuthType.Other,\n",
        "    authParams: {\n",
        "      authenticationDetailsProvider: await ResourcePrincipalAuthenticationDetailsProvider.builder()\n",
        "    },\n",
        "  }\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also instantiate the OCI Generative AI chat classes using `GenerativeAiInferenceClient` that you create on your own. This way you control the creation and configuration of the client to suit your specific needs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "javascript"
        }
      },
      "outputs": [],
      "source": [
        "import { ConfigFileAuthenticationDetailsProvider } from \"oci-common\";\n",
        "import { GenerativeAiInferenceClient } from \"oci-generativeaiinference\";\n",
        "import { OciGenAiCohereChat } from \"@langchain/community/chat_models/oci_genai/cohere_chat\";\n",
        "\n",
        "const client = new GenerativeAiInferenceClient({\n",
        "  authenticationDetailsProvider: new ConfigFileAuthenticationDetailsProvider()\n",
        "});\n",
        "\n",
        "const cohereLlm = new OciGenAiCohereChat({\n",
        "  compartmentId: \"oci.compartment...\",\n",
        "  onDemandModelId: \"cohere.command-r-plus-08-2024\",\n",
        "  client\n",
        "});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Invocation\n",
        "In this example, we make a simple call to the OCI Generative AI service while leveraging the power of the `cohere.command-r-plus-08-2024` model.\n",
        "Please note that you can pass additional request parameters under the `requestParams` key as shown in the `invoke` call below. For more information please see the [Cohere request parameters](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai-inference/20231130/datatypes/CohereChatRequest) (the `apiFormat`, `chatHistory`, `isStream`, `message` & `stopSequences` parameters are automatically generated or inferred from the call context) and the [Generic request parameters](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai-inference/20231130/datatypes/GenericChatRequest) (the `apiFormat`, `isStream`, `messages` & `stop` parameters are automatically generated or inferred from the call context).\n",
        "\n",
        "If you wish to specify the chat history for a Cohere request, the list of messages passed into the request will be analyzed and split into the current message and history messages. The last `Human` message sent in the list (regardless of it's position in the list) will be considered as the `message` parameter for the request and the rest of the messages will be added to the `chatHistory` parameter. If there are more than one `Human` messages, the very last one will be considered as the `message` to be sent to the LLM in the current request and the other will be appended to the `chatHistory`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "javascript"
        }
      },
      "outputs": [],
      "source": [
        "import { OciGenAiCohereChat } from \"@langchain/community/chat_models/oci_genai/cohere_chat\";\n",
        "\n",
        "const llm = new OciGenAiCohereChat({\n",
        "  compartmentId: \"oci.compartment...\",\n",
        "  onDemandModelId: \"cohere.command-r-plus-08-2024\"\n",
        "});\n",
        "\n",
        "const result = await llm.invoke(\"Tell me a joke about beagles\", {\n",
        "  requestParams: {\n",
        "    temperature: 1,\n",
        "    maxTokens: 300\n",
        "  }\n",
        "});\n",
        "\n",
        "console.log(result);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AIMessage {\n",
        "  \"content\": \"Why did the beagle cross the road?\\n\\nBecause he was tied to the chicken!\\n\\nI hope you enjoyed the joke! Would you like to hear another one?\",\n",
        "  \"additional_kwargs\": {},\n",
        "  \"response_metadata\": {},\n",
        "  \"tool_calls\": [],\n",
        "  \"invalid_tool_calls\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional information\n",
        "For additional information, please checkout the [OCI Generative AI service documentation](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm).\n",
        "\n",
        "If you are interested in the python version of this integration, you can find more information [here](https://python.langchain.com/docs/integrations/llms/oci_generative_ai/)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "oci_langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
